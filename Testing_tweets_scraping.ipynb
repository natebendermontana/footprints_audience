{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808ac66c",
   "metadata": {},
   "source": [
    "### Import packages & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb69ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9bb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACADEMIC ACCOUNT. Set connection to Tweepy. I've put my API keys in a .py file called API_keys.py\n",
    "from my_api_keys import bearer_token\n",
    "tweepyclient = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e059772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "\n",
    "start_time = \"2022-11-07T00:00:00Z\"\n",
    "end_time = \"2022-11-08T00:00:00Z\"\n",
    "query = '#trailrunning OR #running OR #run OR #trail OR #trailrunner OR #trailrun -is:retweet lang:en'\n",
    "response_perpg = 10\n",
    "num_pgs = 3\n",
    "audience_type = \"trailrunning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4599892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulltweets(query, start_time, end_time, response_perpg, num_pgs):\n",
    "\n",
    "    tweet_list = []\n",
    "    func_start = time.time()\n",
    "    \n",
    "    # response is like a \"page\" of tweets. Num of tweets per \"page\" is set by \"max_results\"\n",
    "    for response in tweepy.Paginator(tweepyclient.search_all_tweets, \n",
    "                                     query = query,\n",
    "                                     user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                     tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                     expansions = 'author_id',\n",
    "                                     start_time = start_time,\n",
    "                                     end_time = end_time,\n",
    "                                     max_results=response_perpg):  #pull \"response_perpg\" tweets per response\n",
    "\n",
    "        if len(tweet_list)+1 > num_pgs :         # Flag to quit when we need to\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(1)  # only 1 request per second allowed\n",
    "            #print(f'page {len(tweet_list)+1}')\n",
    "            tweet_list.append(response)\n",
    "\n",
    "    func_end = time.time()\n",
    "    print(f'Pulled {len(tweet_list)} pages and {len(tweet_list)*response_perpg} tweets')\n",
    "    print('Pull time was {} minutes.'.format(round(func_end - func_start)/60, 2))    \n",
    "    \n",
    "    return(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f3b9873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 3 pages and 30 tweets\n",
      "Pull time was 0.06666666666666667 minutes.\n"
     ]
    }
   ],
   "source": [
    "tweet_list = pulltweets(query, start_time, end_time, response_perpg, num_pgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa7d10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processtweets(tweet_list):\n",
    "    \n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    \n",
    "    # Loop through each response object\n",
    "    for response in tweet_list:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        for user in response.includes['users']:\n",
    "            user_dict[user.id] = {'username': user.username, \n",
    "                                  'followers': user.public_metrics['followers_count'],\n",
    "                                  'tweets': user.public_metrics['tweet_count'],\n",
    "                                  'description': user.description,\n",
    "                                  'location': user.location\n",
    "                                 }\n",
    "        for tweet in response.data:\n",
    "            # For each tweet, find the author's information\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "            # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "            result.append({'user_id': tweet.author_id, \n",
    "                           'username': author_info['username'],\n",
    "                           'follower_count': author_info['followers'],\n",
    "                           'total_tweets': author_info['tweets'],\n",
    "                           'description': author_info['description'],\n",
    "                           'location': author_info['location'],\n",
    "                           'tweet_id' : tweet.id,\n",
    "                           'text': tweet.text,\n",
    "                           'created_at': tweet.created_at,\n",
    "                           'retweets_count': tweet.public_metrics['retweet_count'],\n",
    "                           'replies_count': tweet.public_metrics['reply_count'],\n",
    "                           'likes_count': tweet.public_metrics['like_count'],\n",
    "                           'quote_count': tweet.public_metrics['quote_count']\n",
    "                          })\n",
    "\n",
    "    # Change this list of dictionaries into a dataframe\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    # Let's see how long it took to grab all tweets and how many were pulled\n",
    "    print('Processed {} tweets'.format(len(df)))\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b83c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullandprocess(query, start_time, end_time, response_perpg, num_pgs, audience_type):\n",
    "\n",
    "    tweet_list = pulltweets(query, start_time, end_time, response_perpg, num_pgs)\n",
    "    \n",
    "    tweetsdf = processtweets(tweet_list)\n",
    "    \n",
    "    # Obtain timestamp in a readable format\n",
    "    to_csv_timestamp = datetime.date.today().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Define working path\n",
    "    path = os.getcwd()\n",
    "    \n",
    "    # define filename location, timestamp, and custom audience type\n",
    "    filename = path + '/data/' + to_csv_timestamp + '_tweets_' + audience_type + '.csv'\n",
    "    \n",
    "    # Store dataframe in csv with creation date timestamp\n",
    "    tweetsdf.to_csv(filename, index = False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c36c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 3 pages and 30 tweets\n",
      "Pull time was 0.06666666666666667 minutes.\n",
      "Processed 30 tweets\n"
     ]
    }
   ],
   "source": [
    "pullandprocess(query, start_time, end_time, response_perpg, num_pgs, audience_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2333b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a770d1c",
   "metadata": {},
   "source": [
    "## Ignore for now: testing adding followers & following to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ca7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followers_id(person):\n",
    "    followersid = []\n",
    "    count=0\n",
    "    user=api.get_user(screen_name=person)\n",
    "    user_id=user.id\n",
    "    number_of_followers=user.followers_count\n",
    "    status = tweepy.Cursor(api.get_follower_ids, screen_name=person, tweet_mode=\"extended\").items()\n",
    "    for i in range(0,number_of_followers):\n",
    "        follower=next(status)\n",
    "        followersid.append(follower)\n",
    "        count += 1\n",
    "    return followersid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_followers_id(\"37chandler\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
